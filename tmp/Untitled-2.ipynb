{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pptx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m declarative_base, sessionmaker\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpptx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Presentation\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpptx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Inches\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# URL of the webpage containing the data\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pptx'"
     ]
    }
   ],
   "source": [
    "import mechanicalsoup\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "import re\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "\n",
    "# URL of the webpage containing the data\n",
    "url = 'https://www.ncei.noaa.gov/access/monitoring/monthly-report/global/202313'\n",
    "\n",
    "# Create a browser object\n",
    "browser = mechanicalsoup.StatefulBrowser()\n",
    "browser.open(url)\n",
    "\n",
    "# Fetch the content\n",
    "page = browser.get_current_page()\n",
    "\n",
    "# Extract the table containing the data\n",
    "table = page.find('table')\n",
    "\n",
    "if table is None:\n",
    "    print(\"No table found on the webpage.\")\n",
    "    exit()\n",
    "\n",
    "# Function to sanitize column names\n",
    "def sanitize_column_name(name):\n",
    "    return re.sub(r'\\W|^(?=\\d)', '_', name).lower()\n",
    "\n",
    "# Extract headers\n",
    "headers = [sanitize_column_name(header.text.strip()) for header in table.find_all('th')]\n",
    "print(\"Headers:\", headers)\n",
    "\n",
    "# Extract rows and handle rows with missing columns by filling with None\n",
    "rows = []\n",
    "for row in table.find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    if cells:\n",
    "        row_data = [cell.text.strip() for cell in cells]\n",
    "        if len(row_data) < len(headers):\n",
    "            row_data.extend([None] * (len(headers) - len(row_data)))\n",
    "        rows.append(row_data)\n",
    "    else:\n",
    "        print(\"Skipping row due to column mismatch:\", [cell.text.strip() for cell in cells])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Rename columns with typos\n",
    "df.rename(columns={'life_exectancy': 'life_expectancy'}, inplace=True)\n",
    "\n",
    "# Debugging: Check initial DataFrame structure and types\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "# Define SQLAlchemy model dynamically\n",
    "Base = declarative_base()\n",
    "\n",
    "# Create a dictionary of columns for the SQLAlchemy model\n",
    "columns = {\n",
    "    '__tablename__': 'ecological_footprint',\n",
    "    'id': Column(Integer, primary_key=True, autoincrement=True)\n",
    "}\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_string_dtype(df[column]):\n",
    "        columns[column] = Column(String)\n",
    "    elif pd.api.types.is_integer_dtype(df[column]):\n",
    "        columns[column] = Column(Integer)\n",
    "    elif pd.api.types.is_float_dtype(df[column]):\n",
    "        columns[column] = Column(Float)\n",
    "\n",
    "# Define the dynamic model\n",
    "EcologicalFootprint = type('EcologicalFootprint', (Base,), columns)\n",
    "\n",
    "# Create an engine that connects to the SQLite database\n",
    "engine = create_engine('sqlite:///GlobalEcologicalFootprint.db', echo=True)\n",
    "\n",
    "# Drop the existing table if it exists\n",
    "Base.metadata.drop_all(engine, [Base.metadata.tables.get('ecological_footprint')])\n",
    "\n",
    "# Create all tables in the engine\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Create a session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Insert data into the database\n",
    "for _, row in df.iterrows():\n",
    "    row_data = {column: row[column] for column in df.columns}\n",
    "    try:\n",
    "        footprint_data = EcologicalFootprint(**row_data)\n",
    "        session.add(footprint_data)\n",
    "    except TypeError as e:\n",
    "        print(f\"Error inserting row: {row_data}\")\n",
    "        print(e)\n",
    "\n",
    "# Commit the transaction\n",
    "session.commit()\n",
    "\n",
    "# Close the session\n",
    "session.close()\n",
    "\n",
    "# Read the data back from the database to display it\n",
    "df_from_db = pd.read_sql_table('ecological_footprint', engine)\n",
    "print(\"DataFrame from the database:\")\n",
    "print(df_from_db)\n",
    "\n",
    "# Create a PowerPoint presentation\n",
    "prs = Presentation()\n",
    "\n",
    "# Title slide\n",
    "slide_layout = prs.slide_layouts[0]\n",
    "slide = prs.slides.add_slide(slide_layout)\n",
    "title = slide.shapes.title\n",
    "subtitle = slide.placeholders[1]\n",
    "title.text = \"Global Ecological Footprint Data Analysis\"\n",
    "subtitle.text = \"Summary of Data Extraction, Cleaning, Storage, and Visualization\"\n",
    "\n",
    "# Slide 1: Introduction\n",
    "slide_layout = prs.slide_layouts[1]\n",
    "slide = prs.slides.add_slide(slide_layout)\n",
    "title = slide.shapes.title\n",
    "title.text = \"Introduction\"\n",
    "content = slide.placeholders[1]\n",
    "content.text = (\n",
    "    \"This presentation provides an overview of the process of extracting, \"\n",
    "    \"cleaning, storing, and visualizing global ecological footprint data.\"\n",
    ")\n",
    "\n",
    "# Slide 2: Data Extraction Process\n",
    "slide_layout = prs.slide_layouts[1]\n",
    "slide = prs.slides.add_slide(slide_layout)\n",
    "title = slide.shapes.title\n",
    "title.text = \"Data Extraction Process\"\n",
    "content = slide.placeholders[1]\n",
    "content.text = (\n",
    "    \"1. URL: 'https://www.ncei.noaa.gov/access/monitoring/monthly-report/global/202313'\\n\"\n",
    "    \"2. Used MechanicalSoup to open and fetch the webpage content.\\n\"\n",
    "    \"3. Extracted table headers and rows from the HTML table.\\n\"\n",
    "    \"4. Sanitized column names to ensure they are valid Python identifiers.\\n\"\n",
    ")\n",
    "\n",
    "# Slide 3: Data Cleaning\n",
    "slide_layout = prs.slide_layouts[1]\n",
    "slide = prs.slides.add_slide(slide_layout)\n",
    "title = slide.shapes.title\n",
    "title.text = \"Data Cleaning\"\n",
    "content = slide.placeholders[1]\n",
    "content.text = (\n",
    "    \"1. Converted extracted data into a pandas DataFrame.\\n\"\n",
    "    \"2. Renamed columns with typos (e.g., 'life_exectancy' to 'life_expectancy').\\n\"\n",
    "    \"3. Removed non-numeric characters and converted columns to appropriate types.\\n\"\n",
    ")\n",
    "\n",
    "# Slide 4: Database Storage\n",
    "slide_layout = prs.slide_layouts[1]\n",
    "slide = prs.slides.add_slide(slide_layout)\n",
    "title = slide.shapes.title\n",
    "title.text = \"Database Storage\"\n",
    "content = slide.placeholders[1]\n",
    "content.text = (\n",
    "    \"1. Created an SQLite database using SQLAlchemy.\\n\"\n",
    "    \"2. Defined a dynamic model for the data using SQLAlchemy.\\n\"\n",
    "    \"3. Inserted the cleaned data into the SQLite database.\\n\"\n",
    "    \"4. Verified data insertion by reading the data back from the database into a DataFrame.\\n\"\n",
    ")\n",
    "\n",
    "# Slide 5: Visualization\n",
    "slide_layout = prs.slide_layouts[1]\n",
    "slide = prs.slides.add_slide(slide_layout)\n",
    "title = slide.shapes.title\n",
    "title.text = \"Visualization\"\n",
    "content = slide.placeholders[1]\n",
    "content.text = (\n",
    "    \"1. Used matplotlib and seaborn for data visualization.\\n\"\n",
    "    \"2. Created various plots such as histograms, box plots, scatter plots, and heatmaps.\\n\"\n",
    "    \"3. Displayed the initial DataFrame created from the HTML table.\\n\"\n",
    ")\n",
    "\n",
    "# Slide 6: Sample Data Table\n",
    "slide_layout = prs.slide_layouts[5]\n",
    "slide = prs.slides.add_slide(slide_layout)\n",
    "title = slide.shapes.title\n",
    "title.text = \"Sample Data\"\n",
    "rows, cols = df_from_db.shape\n",
    "table = slide.shapes.add_table(rows+1, cols, Inches(0.5), Inches(1.5), Inches(9), Inches(5)).table\n",
    "\n",
    "# Set column names\n",
    "for i, column_name in enumerate(df_from_db.columns):\n",
    "    table.cell(0, i).text = column_name\n",
    "\n",
    "# Add data to the table\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        table.cell(i+1, j).text = str(df_from_db.iat[i, j])\n",
    "\n",
    "# Slide 7: Conclusion\n",
    "slide_layout = prs.slide_layouts[1]\n",
    "slide = prs.slides.add_slide(slide_layout)\n",
    "title = slide.shapes.title\n",
    "title.text = \"Conclusion\"\n",
    "content = slide.placeholders[1]\n",
    "content.text = (\n",
    "    \"This presentation summarized the process of extracting, cleaning, storing, \"\n",
    "    \"and visualizing global ecological footprint data. The data extraction was \"\n",
    "    \"performed using MechanicalSoup, data cleaning with pandas, storage with \"\n",
    "    \"SQLAlchemy and SQLite, and visualization with matplotlib and seaborn.\"\n",
    ")\n",
    "\n",
    "# Save the presentation\n",
    "prs.save('Global_Ecological_Footprint_Summary.pptx')\n",
    "print(\"PowerPoint presentation created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
